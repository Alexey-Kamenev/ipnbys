{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A few MNIST experiements with TensorFlow\n",
    "\n",
    "First, setup TensorFlow, numpy and other libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plot\n",
    "from IPython import display\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "mnist = read_data_sets(\"./data/\", one_hot=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotImages(images, imagesToShow = 10):\n",
    "    #plot.rcParams[\"figure.figsize\"] = 10, 10\n",
    "    imgs = images[np.random.randint(images.shape[0], size=imagesToShow)]\n",
    "    plot.imshow(np.hstack([(1.0 - i).reshape((28, 28)) for i in imgs]), cmap=\"gray\")\n",
    "    #display.display(plot.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of images from the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABECAYAAACRbs5KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJnCHzuFwOGYCd+gcDodjJvw/7y+xgnH3I18AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f552ef69790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotImages(mnist.train.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define various layer types (inputs, fully-connected, convolutional, loss etc):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_size = 28\n",
    "label_size = 10\n",
    "# Input image dimensions (single channel)\n",
    "input_dims = [image_size, image_size, 1]\n",
    "\n",
    "# Features and labels\n",
    "def inputs():\n",
    "    features = tf.placeholder(tf.float32, shape=[None] + input_dims, name=\"features\")\n",
    "    labels = tf.placeholder(tf.float32, shape=[None], name=\"labels\")\n",
    "    return features, labels\n",
    "\n",
    "# Cross-entropy loss with softmax activation function\n",
    "def ce_sm_loss(logits, labels):\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        ce = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=tf.cast(labels, tf.int32), name=\"ce\")\n",
    "        return tf.reduce_mean(ce, name=\"ce_mean\")\n",
    "\n",
    "# Outputs (probabilities)\n",
    "def probs_layer(logits):\n",
    "    return tf.nn.softmax(logits)\n",
    "\n",
    "# Fully-connected layer\n",
    "# Helper function\n",
    "def _fc_layer(x, size):\n",
    "    # Flatten dims for the fully-connected layer.\n",
    "    x_flat = tf.reshape(x, [-1, x.get_shape()[1:].num_elements()])\n",
    "    shape = [x_flat.get_shape()[1].value, size]\n",
    "    W = tf.Variable(tf.truncated_normal(shape, stddev=0.1), name=\"weights\")\n",
    "    b = tf.Variable(tf.constant(0.01, shape=[shape[1]]), name=\"biases\")\n",
    "    return tf.matmul(x_flat, W) + b\n",
    "\n",
    "# FC layer, no activation\n",
    "def fc_layer(x, size, name):\n",
    "    with tf.name_scope(name):\n",
    "        return _fc_layer(x, size)\n",
    "    \n",
    "# FC layer with ReLU\n",
    "def fc_relu_layer(x, size, name=''):\n",
    "    with tf.name_scope(name) as scope:\n",
    "        return tf.nn.relu(_fc_layer(x, size), name=scope)\n",
    "\n",
    "# 2D convolutional layer with ReLU\n",
    "def conv2d_relu_layer(x, kSize, mapCount=1, stride=1, padding='SAME', name=''):\n",
    "    with tf.name_scope(name) as scope:\n",
    "        # assuming x is already a 4D tensor\n",
    "        shape = [kSize, kSize, x.get_shape()[3].value, mapCount]\n",
    "        W = tf.Variable(tf.truncated_normal(shape, stddev=0.1), name=\"weights\")\n",
    "        b = tf.Variable(tf.constant(0.01, shape=[mapCount]),    name=\"biases\")\n",
    "        conv = tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding=padding, name=\"conv\")\n",
    "        return tf.nn.relu(conv + b, name=scope)\n",
    "\n",
    "# Spatial max pooling layer\n",
    "def max_pool(x, kSize, stride=0, name=''):\n",
    "    if stride <= 0:\n",
    "        stride = kSize\n",
    "    with tf.name_scope(name):\n",
    "        return tf.nn.max_pool(x, ksize=[1, kSize, kSize, 1], strides=[1, stride, stride, 1], \n",
    "                              padding='SAME', name=\"pool\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network topologies\n",
    "\n",
    "### Simple, one-hidden layer net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_net(features):\n",
    "    h1_size = 200\n",
    "    h1 = fc_relu_layer(features, h1_size, \"h1\")\n",
    "    return h1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional net:\n",
    "5 layers: `convolution -> max pool -> convolution -> max pool -> fully-connected`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net_01(features):\n",
    "    conv1 = conv2d_relu_layer(features, 5, 32, name='conv1')\n",
    "    pool1 = max_pool(conv1, 2, name='pool1')\n",
    "    conv2 = conv2d_relu_layer(pool1, 5, 32, name='conv2')\n",
    "    pool2 = max_pool(conv2, 2, name='pool2')\n",
    "    fc1 = fc_relu_layer(pool2, 128, 'fc1')\n",
    "    return fc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph visualization from TensorBoard:\n",
    "![conv_net_01](images/conv_01_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations and actions\n",
    "Define operations such as training and actions like train, evaluate and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training step operation\n",
    "def create_train_op(loss, learning_rate, momentum):\n",
    "    tf.summary.scalar(loss.op.name, loss)\n",
    "    step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    return step\n",
    "\n",
    "def get_next_feed(dataset, batch_size, features, labels):\n",
    "    f, l = dataset.next_batch(batch_size)\n",
    "    return {features: f.reshape([batch_size] + input_dims), labels: l}\n",
    "    \n",
    "# Training action - performs training using provided train step and inputs\n",
    "def do_train(sess, train_step, loss, next_feed, batch_size, epoch_size, num_epochs, \n",
    "             summary_op, summary_writer):\n",
    "    for epoch in range(0, num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for i in range(0, epoch_size, batch_size):\n",
    "            cur_batch_size = min(batch_size, epoch_size - i)\n",
    "            feed_dict = next_feed(cur_batch_size)\n",
    "            _, loss_val = sess.run([train_step, loss], feed_dict=feed_dict)\n",
    "            epoch_loss += np.sum(loss_val)\n",
    "            if i % 1000 == 0:\n",
    "                summary_str = sess.run(summary_op, feed_dict=feed_dict)\n",
    "                summary_writer.add_summary(summary_str, epoch * epoch_size + i)\n",
    "                summary_writer.flush()\n",
    "                \n",
    "        print(\"Epoch %d: loss = %0.05f\" % (epoch, epoch_loss / epoch_size))\n",
    "        \n",
    "# Evaluation of a model on a given dataset    \n",
    "def do_eval(sess, logits, labels, next_feed, batch_size, epoch_size):\n",
    "    batch_correct = tf.reduce_sum(tf.cast(tf.nn.in_top_k(logits, tf.cast(labels, tf.int32), 1), tf.int32))\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(0, epoch_size, batch_size):\n",
    "        cur_batch_size = min(batch_size, epoch_size - i)\n",
    "        feed_dict = next_feed(cur_batch_size)\n",
    "        correct += np.sum(sess.run(batch_correct, feed_dict=feed_dict))\n",
    "        total += cur_batch_size\n",
    "\n",
    "    return total, correct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and execute the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss = 0.00412\n",
      "Test set accuracy: 0.9675 (9675/10000)\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate(net):\n",
    "    with tf.Graph().as_default():\n",
    "        # Build the network for training\n",
    "        features, labels = inputs()\n",
    "        \n",
    "        logits = fc_layer(net(features), label_size, \"logits\")\n",
    "        probs = probs_layer(logits)\n",
    "        loss = ce_sm_loss(logits, labels)\n",
    "\n",
    "        # Create train operation\n",
    "        train_step = create_train_op(loss, learning_rate=0.1, momentum=0)\n",
    "\n",
    "        g = tf.get_default_graph()\n",
    "        ww = g.get_tensor_by_name(\"conv1/weights:0\")\n",
    "        #ww1 = tf.transpose(tf.split(3, 32, ww)[0], [3, 0, 1, 2])\n",
    "        ww1 = tf.reshape(ww, (1, 5, 5 * 32, 1))\n",
    "        tf.summary.image(\"ww\", ww1, max_outputs=1)\n",
    "        \n",
    "        # Summary operation\n",
    "        summary_op = tf.summary.merge_all()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            # TensorBoard needs a separate folder for each run.\n",
    "            log_dir = \"/data/tf/log/\" + time.strftime(\"%Y%m%d%H%M%S\")\n",
    "            summary_writer = tf.summary.FileWriter(log_dir, sess.graph)\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            # Train model\n",
    "            batch_size = 64\n",
    "            epoch_size = mnist.train.num_examples\n",
    "            num_epochs = 1\n",
    "            next_feed = lambda b: get_next_feed(mnist.train, b, features, labels)\n",
    "            do_train(sess, train_step, loss, next_feed, batch_size, epoch_size, num_epochs,\n",
    "                    summary_op, summary_writer)\n",
    "\n",
    "            # Evaluate model on test dataset\n",
    "            next_feed = lambda b: get_next_feed(mnist.test, b, features, labels)\n",
    "            total, correct_count = do_eval(sess, probs, labels, next_feed, 100, mnist.test.num_examples)\n",
    "            print('Test set accuracy: %0.04f (%d/%d)' % (correct_count / float(total), correct_count, total))\n",
    "\n",
    "train_and_evaluate(capsule_net_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training fully-connected net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_and_evaluate(simple_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss graph for fully-connected net (from TensorBoard):\n",
    "![fc_loss](images/fc_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training convolutional net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_and_evaluate(conv_net_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss graph for convolutional net (from TensorBoard):\n",
    "![fc_loss](images/conv_01_loss.png)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
